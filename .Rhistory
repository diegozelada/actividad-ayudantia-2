#normalizo las variables para así poder trabajar todas en la misma escala
sampleonorm=normalize(sampleo[3:6])
library
library
library
library(dplyr)
library(distances)
library(ggplot2)
library(outliers)
library(cluster)
library(purrr)
library(factoextra)
library(BBmisc)
library(dbscan)
#normalizo las variables para así poder trabajar todas en la misma escala
sampleonorm=normalize(sampleo[3:6])
View(sampleonorm)
modeln = kmeans(sampleonorm, centers=5)
modeln$cluster <- as.factor(modeln$cluster)
ggplot(sampleonorm, aes( Assets, Credit,color=modeln$cluster)) +geom_point()+theme(axis.text=element_text(size=12),axis.title=element_text(size=18))
summary(model$cluster)
model$centers
ggplot(sampleonorm, aes( Income, Assets,color=modeln$cluster)) +geom_point()+theme(axis.text=element_text(size=12),axis.title=element_text(size=18))
ggplot(sampleonorm, aes( Income, Contr_Margin,color=modeln$cluster)) +geom_point()+theme(axis.text=element_text(size=12),axis.title=element_text(size=18))
ggplot(sampleonorm, aes( Assets , Contr_Margin,color=modeln$cluster)) +geom_point()+theme(axis.text=element_text(size=12),axis.title=element_text(size=18))
modeln$centers
modeln$cluster
modeln$size
summary(modeln$cluster)
library("e1071")
cm <- cmeans(seg2, 5)
pertenencia=cm$membership
pertenencia=cm$membership
cm <- cmeans(seg2, 5)
library("e1071")
cm <- cmeans(modeln, 5)
pertenencia=cm$membership
pertenencia
library(factoextra)
fviz_cluster(list(data = sampleonorm , cluster=cm$cluster),
ellipse.type = "norm",
ellipse.level = 0.68,
palette = "jco",
ggtheme = theme_minimal())
fviz_nbclust(seg.df, kmeans, method = c("wss"))
fviz_nbclust(seg.df, kmeans, method = c("silhouette"))
setwd("C:/Users/Diego Zelada/OneDrive/Documents")
data <- read.csv(file.choose(), header = TRUE, sep = ",")
head(data)
View(data)
data <- read.csv(file.choose(), header = TRUE, sep = ";")
head(data)
View(data)
View(data)
library(arules)
install.packages("arules")
install.packages("arulesViz")
library(arules)
library(arulesViz)
summary(data)
itemFrequencyPlot(data,topN=20,type="relative")
itemFrequencyPlot(data,topN=20,type="relative")
tr <- read.transactions("Boletas_sublinea_20000_ok.csv", format = 'basket', sep=';')
itemFrequencyPlot(data,topN=20,type="relative")
library(ggplot2)
itemFrequencyPlot(data,topN=20,type="relative")
?itemFrequencyPlot
data=data[,-1]
rules=apriori(data,parameter=list(supp=0,0500025))
setwd("D:\Universidad\Minería de datos 2")
C:/Users/Diego Zelada/OneDrive/Documents
setwd("C:/Users/Diego Zelada/OneDrive/Documents")
data <- read.csv(file.choose(), header = TRUE, sep = ";")
datasanguchez <- read.csv(file.choose(), header = TRUE, sep = ";")
datasanguchez <- read.csv(file.choose(), header = TRUE, sep = ";")
head(data)
View(datasanguchez)
library (tidyverse)
library(quanteda)
library(ggplot2)
library(utf8)
setwd("C:/Users/Diego Zelada/OneDrive/Documents")
datatrabajo= read.csv(file.choose(), header = TRUE, sep = ";")
summary(datatrabajo)
##lo segundo que hacemos es reconocer las variables, cuales pueden servir y cuales no##
##vamos aproceder a trabajar con las variables nota, ingredientes, local. Esto debido a que creemos que segun
##el problema que se nos plantea es conveniente trabajar con estas variables ##
datareal1 = datatrabajo[,-c(1,3,4,7)]
##con la función "sapply" podemos obtener la cantidad de valores NA por columna##
##con la funcion na.omit borramos los valores NA de la bbdd##
sapply(datareal1, function(x)sum(is.na(x)))
datoslimpios= na.omit(datareal1)
## ahora vamos a ordenar los datos de la nota mayor a la menor##
datosordenados= datoslimpios[order(datoslimpios$nota, decreasing = TRUE),]
View(datosordenados)
## solo guardamos los datos que tengan nota 5 ##
notas5= filter(datosordenados, nota=="5")
View(notas5)
textoanalisis= notas5$Ingredientes
## utilizamos la funcion char_tolower() para dejar todas las letras en minuscula y no tener problemas
textoanalisis=char_tolower(textoanalisis)
##convertimos el tipo de archivo
textoanalisis= iconv(textoanalisis, to = "ASCII//TRANSLIT")
##removemos palabras que no nos sirven y obtenemos una matriz que indica los ingredientes que tienen
## las hamburguesas que fueron calificadas en con 5 estrellas
palabras = dfm(textoanalisis, remove = c((stopwords("es")),("ones"), (","),("?"), ("."),("("),(")"),("!")))
View(palabras)
## convertimos un archivo dfm (palabras) en un data frame para poder trabajar en el
ingredientescontar= data.frame(palabras)
View(ingredientescontar)
## sumamos las columnas(ingredientes) y obtenemos la información de los ingredientes que mas se repiten
totalingredientes= colSums(ingredientescontar[, 2:56])
totalingredientes
##ordenamos la importancia de los ingredientes de mayor a menor
ingredientesordenados = totalingredientes[order(totalingredientes, decreasing = TRUE)]
ingredientesordenados
ing = data.frame(ingredientesordenados)
ing= add_rownames(ing, var= "ingredientes")
ing
ing1= ing[-c(15:55),]
ggplot(ing1, aes(x= ingredientes)) + geom_bar()
View(ing1)
ggplot(ing1) + aes(ingredientes, ingredientesordenados, color=factor(clust3)) +
geom_point() + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
ggplot(ing1) + aes(ingredientes, ingredientesordenados) +
geom_point() + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
ggplot(ing1) + aes(ingredientes, ingredientesordenados) +
geom_bar() + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
ggplot(ing1) + aes(ingredientes, ingredientesordenados) +
geom_point() + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
ggplot(ing1) + aes(ingredientes, ingredientesordenados) +
geom_area() + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
ggplot(ing1) + aes(ingredientes, ingredientesordenados) +
geom_bar() + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
last_error()
rlang::last_error()
ggplot(ing1) + aes(Y= ingredientesordenados) +
geom_bar() + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
ggplot(ing1) + aes(ingredientes, ingredientesordenados) +
geom_bar(stat = "count") + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
ggplot(ing1) + aes(Y= ingredientesordenados) +
geom_bar(stat = "count") + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
ggplot(ing1) + aes(X= ingredientes) +
geom_bar(stat = "count") + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
ggplot(ing1, aes(x= ingredientes)) + geom_bar()
ggplot(ing1, aes(x= ingredientes)) + geom_bar(stat = "count")
ggplot(ing1) + aes(x= ingredientes) +
geom_bar(stat = "count") + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
ggplot(ing1) + aes(x= ingredientes) +
geom_bar(stat = "count") + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
ggplot(ing1) + aes(x= ingredientes, y =ingredientesordenados) +
geom_bar() + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
df_base<- ggplot(data=ing1, aes(x=ingredientes))
df_base+geom_bar(stat = "count")
View(ing1)
df_base<- ggplot(data=ing1, aes(x=ingredientes, y= ingredientesordenados))
df_base+geom_bar(stat = "count")
df_base<- ggplot(data=ing, aes(x=ingredientes))
df_base+geom_bar(stat = "count")
df_base<- ggplot(data=ingredientescontar, aes(x=ingredientes))
df_base+geom_bar(stat = "count")
View(ing1)
ggplot(ing1) + aes(x= ingredientes, y =ingredientesordenados) +
geom_bar() + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
ggplot(ing1) + aes(x= ingredientes) +
geom_bar() + theme(axis.text=element_text(size=12), axis.title=element_text(size=18))
summary(ing1)
df_base<- ggplot(data=ing1, aes(x=ingredientes))
df_base+geom_bar(stat = "identity")
ggplot(ing1, aes(x= ingredientes)) + geom_bar(stat = "identity")
ggplot(ing1, aes(x= ingredientes, y= ingredientescontar)) + geom_bar(stat = "identity")
df_base<- geom_bar(stat = "identity")
df_base<- ggplot(data = ing1, aes(x= ingredientes, y=ingredientesordenados))
df_base<- geom_bar(stat = "identity")
## sumamos las columnas(ingredientes) y obtenemos la información de los ingredientes que mas se repiten
totalingredientes= colSums(ingredientescontar[, 2:56])
totalingredientes
View(ingredientescontar)
df_base<- ggplot(data = ingredientescontar, aes(x= totalingredientes))
df_base<- geom_bar(stat = "count")
## sumamos las columnas(ingredientes) y obtenemos la información de los ingredientes que mas se repiten
totalingredientes= colSums(ingredientescontar[, 2:56])
totalingredientes
## convertimos un archivo dfm (palabras) en un data frame para poder trabajar en el
ingredientescontar= data.frame(palabras)
## convertimos un archivo dfm (palabras) en un data frame para poder trabajar en el
ingredientescontar= data.frame(palabras)
datatrabajo= read.csv(file.choose(), header = TRUE, sep = ";")
summary(datatrabajo)
##lo segundo que hacemos es reconocer las variables, cuales pueden servir y cuales no##
##vamos aproceder a trabajar con las variables nota, ingredientes, local. Esto debido a que creemos que segun
##el problema que se nos plantea es conveniente trabajar con estas variables ##
datareal1 = datatrabajo[,-c(1,3,4,7)]
##con la función "sapply" podemos obtener la cantidad de valores NA por columna##
##con la funcion na.omit borramos los valores NA de la bbdd##
sapply(datareal1, function(x)sum(is.na(x)))
datoslimpios= na.omit(datareal1)
## ahora vamos a ordenar los datos de la nota mayor a la menor##
datosordenados= datoslimpios[order(datoslimpios$nota, decreasing = TRUE),]
## solo guardamos los datos que tengan nota 5 ##
notas5= filter(datosordenados, nota=="5")
textoanalisis= notas5$Ingredientes
## utilizamos la funcion char_tolower() para dejar todas las letras en minuscula y no tener problemas
textoanalisis=char_tolower(textoanalisis)
##convertimos el tipo de archivo
textoanalisis= iconv(textoanalisis, to = "ASCII//TRANSLIT")
##removemos palabras que no nos sirven y obtenemos una matriz que indica los ingredientes que tienen
## las hamburguesas que fueron calificadas en con 5 estrellas
palabras = dfm(textoanalisis, remove = c((stopwords("es")),("ones"), (","),("?"), ("."),("("),(")"),("!")))
View(palabras)
## convertimos un archivo dfm (palabras) en un data frame para poder trabajar en el
ingredientescontar= data.frame(palabras)
## sumamos las columnas(ingredientes) y obtenemos la información de los ingredientes que mas se repiten
totalingredientes= colSums(ingredientescontar[, 2:56])
totalingredientes
##ordenamos la importancia de los ingredientes de mayor a menor
ingredientesordenados = totalingredientes[order(totalingredientes, decreasing = TRUE)]
ingredientesordenados
ing = data.frame(ingredientesordenados)
ing= add_rownames(ing, var= "ingredientes")
ing
View(ingredientescontar)
ing1= ing[-c(15:55),]
ing1
View(ing)
View(ing1)
View(ingredientescontar)
totalingredientes
summary(ing1)
## sumamos las columnas(ingredientes) y obtenemos la información de los ingredientes que mas se repiten
totalingredientes= colSums(ingredientescontar[, 2:56])
totalingredientes
ing = data.frame(ingredientesordenados)
ing= add_rownames(ing, var= "ingredientes")
ing
boxplot(ing1, horizontal = TRUE)
barplot(ing1)
barplot(ing1$ingredientesordenados)
barplot(ing1$ingredientes)
hist(ing1)
hist(ing1$ingredientes)
hist(ing1$ingredientesordenados)
hist(y=ing1$ingredientesordenados, x= ing1$ingredientes)
hist( x= ing1$ingredientes, y=ing1$ingredientesordenados)
## sumamos las columnas(ingredientes) y obtenemos la información de los ingredientes que mas se repiten
totalingredientes= colSums(ingredientescontar[, 2:56]) %>%unlist
totalingredientes
##ordenamos la importancia de los ingredientes de mayor a menor
ingredientesordenados = totalingredientes[order(totalingredientes, decreasing = TRUE)]
ingredientesordenados
ing = data.frame(ingredientesordenados)
ing= add_rownames(ing, var= "ingredientes")
ing
ing1= ing[-c(15:55),]
ing1
summary(ing1)
ggplot(ing1, aes(x= ingredientes, y= ingredientescontar)) + geom_bar(stat = "identity")
View(datosordenados)
View(datosordenados)
View(ing)
View(ing1)
library(tools)
## convertimos un archivo dfm (palabras) en un data frame para poder trabajar en el
ingredientescontar= data.frame(unlist(palabras))
## sumamos las columnas(ingredientes) y obtenemos la información de los ingredientes que mas se repiten
totalingredientes= colSums(ingredientescontar[, 2:56])
totalingredientes
##ordenamos la importancia de los ingredientes de mayor a menor
ingredientesordenados = totalingredientes[order(totalingredientes, decreasing = TRUE)]
ingredientesordenados
ing = data.frame(ingredientesordenados)
ing= add_rownames(ing, var= "ingredientes")
ing
ing1= ing[-c(15:55),]
ing1
summary(ing1)
## sumamos las columnas(ingredientes) y obtenemos la información de los ingredientes que mas se repiten
totalingredientes= tibble(word=names(ingredientescontar), count=as.numeric(ingredientescontar))
summary(datasanguchez)
datasanguchez <- read.csv(file.choose(), header = TRUE, sep = ";")
head(data)
summary(datasanguchez)
library("tidyverse")
library("tools")
dim(datasanguchez)
datasanguchez$nota
#filtro mejores hamburguesas
mejoreshamburguesas<- filter(datasanguchez, nota >=5)
#separo ingredientes
mejoresingredientes<- strsplit(mejoreshamburguesas$Ingredientes, split = ",")
ingredientesseparados<- data.frame(unlist(mejoresingredientes))
columnas <- unlist(lapply(columnas, FUN = toTitleCase())
#contador de ingredientes
tabla<- table(columnas)
#contador de ingredientes
tabla <- table(columnas)
columnas <- unlist(lapply(columnas, FUN = toTitleCase())
#contador de ingredientes
tabla <- table(columnas)
tabla <- tibble(word=names(tabla), count= as.numeric(tabla))
tabla <-arrange(tabla, desc(count))
attach(data())
columnas <- unlist(lapply(columnas, FUN = toTitleCase())
#contador de ingredientes
tabla <- table(columnas)
columnas <- unlist(lapply(ingredientesseparados, FUN = toTitleCase())
columnas <- unlist(lapply(ingredientesseparados, FUN = toTitleCase())
columnas <- unlist(lapply(columnas, FUN = toTitleCase)
columnas <- unlist(lapply(columnas, FUN = toTitleCase)
columnas <- unlist(lapply(columnas, FUN = toTitleCase))
columnasqlas <- unlist(lapply(columnasqlas, FUN = toTitleCase))
columnasqlas <- unlist(lapply(columnasqlas , FUN=toTitleCase))
columnasqlas <-unlist(lapply(columnasqlas , FUN=toTitleCase))
data <- read.csv(file.choose(), header = TRUE, sep = ";")
attach(data)
summary(data)
library(tidyverse)
library(tools)
#filtro mejores hamburguesas
mejores<- filter(data, nota >=5)
#separo ingredientes
mejores_ingredientes<- strsplit(mejores$Ingredientes, split= ",")
ingredientes_separados<- data.frame(unlist(mejores_ingredientes))
texto_columnas <- unlist(lapply(texto_columnas , FUN=toTitleCase))
texto_columnas <- unlist(lapply(mejores_ingredientes , FUN=toTitleCase))
#contador de ingredientes
tabla <- table(texto_columnas)
tabla <- tibble(word = names(tabla), count= as.numeric(tabla))
tabla <- arrange(tabla, desc(count))
tabla
View(tabla)
texto_columnas <- unlist(lapply(ingredientes_separados , FUN=toTitleCase))
#contador de ingredientes
tabla <- table(texto_columnas)
tabla <- tibble(word = names(tabla), count= as.numeric(tabla))
tabla <- arrange(tabla, desc(count))
tabla
library (tidyverse)
library(quanteda)
library(ggplot2)
library(utf8)
setwd("C:/Users/Diego Zelada/OneDrive/Documents")
datatrabajo= read.csv(file.choose(), header = TRUE, sep = ";")
summary(datatrabajo)
##lo segundo que hacemos es reconocer las variables, cuales pueden servir y cuales no##
##vamos aproceder a trabajar con las variables nota, ingredientes, local. Esto debido a que creemos que segun
##el problema que se nos plantea es conveniente trabajar con estas variables ##
datareal1 = datatrabajo[,-c(1,3,4,7)]
##con la función "sapply" podemos obtener la cantidad de valores NA por columna##
##con la funcion na.omit borramos los valores NA de la bbdd##
sapply(datareal1, function(x)sum(is.na(x)))
datoslimpios= na.omit(datareal1)
## ahora vamos a ordenar los datos de la nota mayor a la menor##
datosordenados= datoslimpios[order(datoslimpios$nota, decreasing = TRUE),]
## solo guardamos los datos que tengan nota 5 ##
notas5= filter(datosordenados, nota=="5")
textoanalisis= notas5$Ingredientes
## utilizamos la funcion char_tolower() para dejar todas las letras en minuscula y no tener problemas
textoanalisis=char_tolower(textoanalisis)
##convertimos el tipo de archivo
textoanalisis= iconv(textoanalisis, to = "ASCII//TRANSLIT")
##removemos palabras que no nos sirven y obtenemos una matriz que indica los ingredientes que tienen
## las hamburguesas que fueron calificadas en con 5 estrellas
palabras = dfm(textoanalisis, remove = c((stopwords("es")),("ones"), (","),("?"), ("."),("("),(")"),("!")))
## convertimos un archivo dfm (palabras) en un data frame para poder trabajar en el
ingredientescontar= data.frame(unlist(palabras))
texto_columnass<- unlist(lapply(ingredientescontar, FUN = toTitleCase))
tablaa <- table(texto_columnass)
library (tidyverse)
library(quanteda)
library(ggplot2)
library(utf8)
setwd("C:/Users/Diego Zelada/OneDrive/Documents")
datatrabajo= read.csv(file.choose(), header = TRUE, sep = ";")
summary(datatrabajo)
##lo segundo que hacemos es reconocer las variables, cuales pueden servir y cuales no##
##vamos aproceder a trabajar con las variables nota, ingredientes, local. Esto debido a que creemos que segun
##el problema que se nos plantea es conveniente trabajar con estas variables ##
datareal1 = datatrabajo[,-c(1,3,4,7)]
##con la función "sapply" podemos obtener la cantidad de valores NA por columna##
##con la funcion na.omit borramos los valores NA de la bbdd##
sapply(datareal1, function(x)sum(is.na(x)))
datoslimpios= na.omit(datareal1)
## ahora vamos a ordenar los datos de la nota mayor a la menor##
datosordenados= datoslimpios[order(datoslimpios$nota, decreasing = TRUE),]
## solo guardamos los datos que tengan nota 5 ##
notas5= filter(datosordenados, nota=="5")
nota5ingredientes <- strsplit(notas5$Ingredientes, split = ",")
separoingredientes <- data.frame(unlist(nota5ingredientes))
textoanalisis= separoingredientes
## utilizamos la funcion char_tolower() para dejar todas las letras en minuscula y no tener problemas
textoanalisis=char_tolower(textoanalisis)
##convertimos el tipo de archivo
textoanalisis= iconv(textoanalisis, to = "ASCII//TRANSLIT")
##removemos palabras que no nos sirven y obtenemos una matriz que indica los ingredientes que tienen
## las hamburguesas que fueron calificadas en con 5 estrellas
palabras = dfm(textoanalisis, remove = c((stopwords("es")),("ones"),("?"), ("."),("("),(")"),("!")))
## convertimos un archivo dfm (palabras) en un data frame para poder trabajar en el
tabla1 <- table(ingredientescontar)
textoanalisis= nota5ingredientes
## utilizamos la funcion char_tolower() para dejar todas las letras en minuscula y no tener problemas
textoanalisis=char_tolower(textoanalisis)
library (tidyverse)
library(quanteda)
library(ggplot2)
library(utf8)
setwd("C:/Users/Diego Zelada/OneDrive/Documents")
datatrabajo= read.csv(file.choose(), header = TRUE, sep = ";")
summary(datatrabajo)
##lo segundo que hacemos es reconocer las variables, cuales pueden servir y cuales no##
##vamos aproceder a trabajar con las variables nota, ingredientes, local. Esto debido a que creemos que segun
##el problema que se nos plantea es conveniente trabajar con estas variables ##
datareal1 = datatrabajo[,-c(1,3,4,7)]
##con la función "sapply" podemos obtener la cantidad de valores NA por columna##
##con la funcion na.omit borramos los valores NA de la bbdd##
sapply(datareal1, function(x)sum(is.na(x)))
datoslimpios= na.omit(datareal1)
## ahora vamos a ordenar los datos de la nota mayor a la menor##
datosordenados= datoslimpios[order(datoslimpios$nota, decreasing = TRUE),]
## solo guardamos los datos que tengan nota 5 ##
notas5= filter(datosordenados, nota=="5")
nota5ingredientes <- strsplit(notas5$Ingredientes, split = ",")
textoanalisis= nota5ingredientes
## utilizamos la funcion char_tolower() para dejar todas las letras en minuscula y no tener problemas
textoanalisis=char_tolower(textoanalisis)
##convertimos el tipo de archivo
textoanalisis= iconv(textoanalisis, to = "ASCII//TRANSLIT")
textoanalisis= nota5$ingredientes
library (tidyverse)
library(quanteda)
library(ggplot2)
library(utf8)
setwd("C:/Users/Diego Zelada/OneDrive/Documents")
datatrabajo= read.csv(file.choose(), header = TRUE, sep = ";")
summary(datatrabajo)
##lo segundo que hacemos es reconocer las variables, cuales pueden servir y cuales no##
##vamos aproceder a trabajar con las variables nota, ingredientes, local. Esto debido a que creemos que segun
##el problema que se nos plantea es conveniente trabajar con estas variables ##
datareal1 = datatrabajo[,-c(1,3,4,7)]
##con la función "sapply" podemos obtener la cantidad de valores NA por columna##
##con la funcion na.omit borramos los valores NA de la bbdd##
sapply(datareal1, function(x)sum(is.na(x)))
datoslimpios= na.omit(datareal1)
## ahora vamos a ordenar los datos de la nota mayor a la menor##
datosordenados= datoslimpios[order(datoslimpios$nota, decreasing = TRUE),]
## solo guardamos los datos que tengan nota 5 ##
notas5= filter(datosordenados, nota=="5")
textoanalisis= nota5$ingredientes
## utilizamos la funcion char_tolower() para dejar todas las letras en minuscula y no tener problemas
textoanalisis=char_tolower(textoanalisis)
library (tidyverse)
library(quanteda)
library(ggplot2)
library(utf8)
setwd("C:/Users/Diego Zelada/OneDrive/Documents")
datatrabajo= read.csv(file.choose(), header = TRUE, sep = ";")
summary(datatrabajo)
##lo segundo que hacemos es reconocer las variables, cuales pueden servir y cuales no##
##vamos aproceder a trabajar con las variables nota, ingredientes, local. Esto debido a que creemos que segun
##el problema que se nos plantea es conveniente trabajar con estas variables ##
datareal1 = datatrabajo[,-c(1,3,4,7)]
##con la función "sapply" podemos obtener la cantidad de valores NA por columna##
##con la funcion na.omit borramos los valores NA de la bbdd##
sapply(datareal1, function(x)sum(is.na(x)))
datoslimpios= na.omit(datareal1)
## ahora vamos a ordenar los datos de la nota mayor a la menor##
datosordenados= datoslimpios[order(datoslimpios$nota, decreasing = TRUE),]
## solo guardamos los datos que tengan nota 5 ##
notas5= filter(datosordenados, nota=="5")
textoanalisis= notas5$Ingredientes
## utilizamos la funcion char_tolower() para dejar todas las letras en minuscula y no tener problemas
textoanalisis=char_tolower(textoanalisis)
##convertimos el tipo de archivo
textoanalisis= iconv(textoanalisis, to = "ASCII//TRANSLIT")
##removemos palabras que no nos sirven y obtenemos una matriz que indica los ingredientes que tienen
## las hamburguesas que fueron calificadas en con 5 estrellas
palabras = dfm(textoanalisis, remove = c((stopwords("es")),("ones"), (","),("?"), ("."),("("),(")"),("!")))
## convertimos un archivo dfm (palabras) en un data frame para poder trabajar en el
ingredientescontar= data.frame(unlist(palabras))
## sumamos las columnas(ingredientes) y obtenemos la información de los ingredientes que mas se repiten
totalingredientes
##ordenamos la importancia de los ingredientes de mayor a menor
ingredientesordenados = totalingredientes[order(totalingredientes, decreasing = TRUE)]
ingredientesordenados
ing = data.frame(ingredientesordenados)
ing= add_rownames(ing, var= "ingredientes")
ing
getwd
setwd()
library(quanteda)
library(dplyr)
library(tidyverse)
library(utf8)
library(ggplot2)
setwd("D:/Universidad/Minería de datos 2/actividad-ayudantia-2")
primer_tiempo2020 <- read_csv("Primer_Tiempo2020.csv", col_names = TRUE)
#str(primer_tiempo2020)
#attach(primer_tiempo2020)
summary(primer_tiempo2020)
primer_tiempo2020
primer_tiempo2020 <- primer_tiempo2020[,!(colnames(primer_tiempo2020) %in% c("id_partido", "fasepartido", "local", "tiempo","formationUsed", "torneo"))]
primer_tiempo2020
View(primer_tiempo2020)
fh2020 <- primer_tiempo2020[order(primer_tiempo2020$accuratePass, decreasing = TRUE),]
fh2020
fh2020_pases = fh2020[,colnames(primer_tiempo2020) %in% c("equipo", "partido", "accuratePass", "totalPass", "precision_pases")]
fh2020_pases = fh2020_pases[order(fh2020_pases$precision_pases, decreasing = TRUE),]
fh2020_pases
fh2020_tiros <- NULL
fh2020_tiros = fh2020[,colnames(primer_tiempo2020) %in% c("equipo", "partido", "goals", "ontargetScoringAtt", "totalScoringAtt", "blockedScoringAtt", "shotOffTarget", "precision_tiros")]
fh2020_tiros = fh2020_tiros[order(fh2020_tiros$goals, decreasing = TRUE),]
fh2020_tiros
